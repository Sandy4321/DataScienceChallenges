{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64553"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"carsdata_features.csv\", engine='c')\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cat_var = data.select_dtypes(include=['int64'])\n",
    "cont_var = data.select_dtypes(include=['float64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "Les variables sont un mélange de variable catégorielles et variables continues. Les algorithmes de clustering tels que ** k-means ** reposent sur une définition de la distance (par exemple euclidienne) qui s'appliquent uniquement aux variables continues. Pour pouvoir inclure les variables catégorielles, on peut utiliser une variation de k-means qui s'appelle ** k-prototypes **.\n",
    "Les étapes:\n",
    "1. Imputer les valeurs NaN avec la moyenne de la colonne\n",
    "2. Standardiser les variables continues\n",
    "3. Définir une mesure de la qualité de clustering\n",
    "4. Itérations de k-prototypes avec différents nombres de clusters pour optimiser la mesure de clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imputer les valeurs manquantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(np.array(cont_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cont_var_array = imp.transform(np.array(cont_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 86. ],\n",
       "       [ 72.2],\n",
       "       [ 89.9],\n",
       "       [  nan]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#avant imputation\n",
    "np.array(cont_var)[:4,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 86.       ],\n",
       "       [ 72.2      ],\n",
       "       [ 89.9      ],\n",
       "       [ 80.8939467]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apres imputation\n",
    "cont_var_array[:4,:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standardiser les variables continues\n",
    "Le champ de variation de chaques variables doit etre le meme pour que le poids relatif de chaque variable puisse etre equvalent dans la mesure de distance des échantillons. La standardisation consiste en une soustraction de la moyenne et une division par la standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98232348,  0.07834041],\n",
       "       [-1.67257714, -1.75224355],\n",
       "       [ 1.73262149,  2.06502068],\n",
       "       [ 0.        ,  0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaled_cont_var_array = preprocessing.scale(cont_var_array)\n",
    "scaled_cont_var_array[:4,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définir une mesure de qualité du clustering\n",
    "Pour définir la qualité du clustering on utilisa le silouhette index:\n",
    "\\begin{equation*} \\frac{b - a}{max(a,b)}\\end{equation*} \n",
    "\n",
    "Avec a: la distance moyenne d'un point avec tous les autres point de la meme classe,\n",
    "et b : la distance moyenne d'un point avec tous les points d'un autre cluster le plus proche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les variables catégorielles on ne peut pas utiliser la distance euclidienne. On utilise dans ce cas la distance de Hamming qui compte le nombre de diffrences sur toutes les variables catégorielles pour deux échantillons. Les valeurs a et b seront donc une combinaison de distance euclidienne et de Hamming avec un facteur gamma correspondant au ratio du nombres de variable dans les deux catégories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "    kmeans_model = MiniBatchKMeans(n_clusters=3,init='k-means++').fit(scaled_cont_var_array[:10,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64700392094601944"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = kmeans_model.labels_\n",
    "metrics.silhouette_score(scaled_cont_var_array[:10,:], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
